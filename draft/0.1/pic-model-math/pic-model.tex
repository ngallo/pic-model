\documentclass[11pt]{article}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{hyperref}

% Remove end-of-proof square
\renewcommand{\qedsymbol}{}

\title{Authority Propagation Models: PoP vs PoC and the Confused Deputy Problem}
\author{Nicola Gallo}
\date{1 December 2025}

\newtheorem{definition}{Definition}
\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}

\begin{document}
\maketitle

\section{Model}

We formalize the PIC (Provenance Identity Continuity) Model as follows.

Let $P$ be a finite set of principals, $O$ a set of operations, and $R$ a set of resources.
Define a privilege as $(o, r) \in O \times R$.

Execution is modeled as a causal chain of hops:
\[
\pi = \langle (p_0, ops_0), (p_1, ops_1), \dots, (p_n, ops_n) \rangle
\]
where $p_0$ is the originator and each $ops_{i+1} \subseteq ops_i$ (monotonicity).
Here $ops_i \subseteq O \times R$ denotes the set of privileges that principal $p_i$
may exercise at hop $i$.

\begin{definition}[PIC Model]
A system enforces Provenance Identity Continuity if, for every execution chain $\pi$,
the set of privileges at the final hop is bounded by the privileges at the origin:
\[
ops_n \subseteq ops_0
\]
and every privilege exercised at hop $n$ is causally linked to the origin via a verifiable chain.
\end{definition}

\begin{theorem}[PIC Safety]
If the PIC Model holds, no principal can exercise a privilege not present at the origin.
\end{theorem}

\begin{proof}
By construction, $ops_{i+1} \subseteq ops_i$ for all $i$, so $ops_n \subseteq ops_0$.
Thus, any $(o,r) \in ops_n$ must also be in $ops_0$.
Therefore, no privilege can be gained beyond the origin.
\end{proof}

Each principal $p$ has an associated privilege set:
\[
Priv(p) \subseteq O \times R.
\]

A request is a message $req$ sent between principals and may contain a payload.

\section{Confused Deputy}

\begin{definition}[Confused Deputy]
A confused deputy occurs when there exist principals $U$ (user) and $D$ (deputy) such that:
\begin{enumerate}
    \item $(o,r) \notin Priv(U)$,
    \item $(o,r) \in Priv(D)$,
    \item $U$ sends a request $req$ to $D$,
    \item as a consequence of $req$, $D$ executes $(o,r)$.
\end{enumerate}
\end{definition}

This definition does not depend on implementation details,
only on the mismatch of authority and causality.

\paragraph{Classical example (Hardy, 1988).}
A FORTRAN compiler \texttt{FORT}, installed in the privileged directory \texttt{SYSX},
holds ambient authority to write statistics to \texttt{(SYSX)STAT}. A user invokes the
compiler and provides \texttt{(SYSX)BILL} as the debugging output filename.
The compiler opens the target for output using its own authority over \texttt{SYSX},
thereby overwriting \texttt{(SYSX)BILL}. The user never possessed this privilege,
but the deputy exercised it on the user's behalf.

\section{Proof-of-Possession (PoP)}

A token $t$ grants a set of privileges:
\[
Auth(t) \subseteq O \times R.
\]

\paragraph{PoP Semantics.}
Possession implies usability:
if a principal holds $t$, it may exercise all $(o,r)\in Auth(t)$.

PoP systems do not constrain authority by causality or provenance.

\subsection{Vulnerability Condition}

Assume:
\begin{align}
&(\text{write},r) \notin Priv(U) \tag{H1}\\
&(\text{write},r) \in Priv(COMP) \tag{H2}
\end{align}

Here $U$ is the user and $COMP$ is a compiler-like service acting as deputy.

Further assume:

\begin{quote}
The payload of a request may influence control flow in $COMP$,
including code paths that open a resource $r$ using $COMP$'s own authority.
\end{quote}

\begin{theorem}[PoP admits confused deputy]
Under assumptions (H1)--(H2), there exists a request $req^\*$ such that $COMP$
executes $(\text{write},r)$ as a result of processing $req^\*$.
\end{theorem}

\begin{proof}
Since $(\text{write},r)\in Priv(COMP)$, an internal code path may open $r$
under COMP's ambient authority. Because user input influences that path,
there exists a malicious payload $req^\*$ that triggers it. Thus $COMP$
executes a privilege the user does not possess.
\end{proof}

This applies to all artifact-based delegation models:
JWTs, sealed capabilities, cryptographic bearer credentials, etc.

\section{Proof-of-Continuity (PoC / PIC)}

Execution is a causal chain:
\[
p_0 \rightarrow p_1 \rightarrow \dots \rightarrow p_n,
\]
with $p_0 = U$.

Each hop transfers:
\[
ops_{i+1} \subseteq ops_i. \tag{C1}
\]

Let:
\[
\pi = \langle (p_0,ops_0), (p_1,ops_1), \dots, (p_n,ops_n) \rangle.
\]

\subsection{Authorization Rule}
$(o,r)$ is authorized at the final hop iff:
\[
(o,r) \in \bigcap_{i=0}^{n} ops_i.
\]

Since the chain is monotonic decreasing:
\[
\bigcap_{i=0}^{n} ops_i = ops_n.
\]

Thus no hop may acquire authority not already present at the origin.

\begin{lemma}[Irreversible loss of authority]
If $(o,r)\notin ops_j$ for some hop $j$, then 
$(o,r)\notin ops_k$ for all $k \ge j$.
\end{lemma}

\begin{proof}
By monotonicity, $ops_k \subseteq ops_j$ for all $k\ge j$.
\end{proof}

\section{Safety Property}

\begin{definition}[Origin-bounded authority]
A model enforces origin-bounded authority if every executable privilege
at hop $n$ was originally granted at hop $0$.
\end{definition}

\begin{theorem}[PoC prevents confused deputy]
If $ops_0 = \{(\text{convert},r)\}$, then $(\text{write},r)$ can never be authorized.
\end{theorem}

\begin{proof}
$(\text{write},r)\notin ops_0$ and $ops_{i+1}\subseteq ops_i$.
Thus $(\text{write},r)\notin ops_n$.
\end{proof}

\section{Elimination of the Confused Deputy}

The Confused Deputy requires an ontological assumption:
that authority is a transferable or rebindable object that a principal may
hold or reinterpret on behalf of another.

PIC eliminates this ontology entirely.

\begin{theorem}[Confused Deputy is non-formulable under PIC]
In any system satisfying PIC monotonicity $ops_{i+1}\subseteq ops_i$
and origin-bounded authority $ops_n \subseteq ops_0$,
the Confused Deputy conditions cannot be jointly satisfied.
\end{theorem}

\begin{proof}
The Confused Deputy requires:
\[
(o,r)\notin ops_0 \quad \text{and} \quad (o,r)\in ops_k \text{ for some } k>0.
\]
But PIC enforces:
\[
ops_k \subseteq ops_0 \;\; \forall k.
\]
Thus if $(o,r)\notin ops_0$, it cannot appear in any $ops_k$.
The privilege mismatch required for a Confused Deputy is impossible.
\end{proof}

\paragraph{Interpretation.}
Authority in PIC is not something that a subject \emph{has};
it is a continuity property of the execution chain.
Since no hop may introduce or reinterpret authority absent at the origin,
no deputy can be ``confused.''  
The attack does not occur; it is not even definable in the model.

\section{Discussion}

PoP systems conflate authority and possession, enabling confused deputy attacks.
PIC/PoC systems propagate only non-expansive subsets of authority,
ensuring no downstream service can perform operations not authorized at the origin.

\section*{Related Work}

The confused deputy was formalized by Hardy (1988).
Capability theory originates in Dennis \& Van Horn (1966).
Confinement was introduced by Lampson (1973).
EROS (Shapiro et al., 1999) and seL4 (Klein et al., 2009) provide strong isolation.
Distributed authorization theories include Abadi et al. (1993--2000) and SPKI (RFC 2693).
Modern zero-trust models (BeyondCorp, SPIFFE) apply causal constraints similar in spirit.

\section*{Acknowledgments}

The author used automated language assistance tools for grammar and phrasing.
All conceptual contributions, models, and proofs are solely the author's.

\section*{References}

\begin{enumerate}
\item N. Gallo.
   ``PIC Model â€” Provenance Identity Continuity for Distributed Execution Systems.''
   Zenodo (2025). \url{https://zenodo.org/records/17777421}.

\item N. Hardy. ``The Confused Deputy.'' Operating Systems Review, 1988.

\item Dennis \& Van Horn. ``Programming Semantics for Multiprogrammed Computations.'' CACM, 1966.

\item B. Lampson. ``A Note on the Confinement Problem.'' CACM, 1973.

\item Shapiro et al. ``EROS: A Fast Capability System.'' SOSP, 1999.

\item Klein et al. ``seL4: Formal Verification of an OS Kernel.'' SOSP, 2009.

\item Abadi et al. ``A Calculus for Access Control.'' TOPLAS, 1993--2000.

\item C. Ellison et al. ``SPKI Certificate Theory.'' RFC 2693, IETF, 1999.

\item Google. ``BeyondCorp: A New Approach to Enterprise Security.'' 2014.

\item SPIFFE Working Group. ``Secure Production Identity Framework for Everyone.''
\end{enumerate}

\end{document}
